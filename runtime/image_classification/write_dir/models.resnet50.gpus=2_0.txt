0
came here
Now initiating process group...
Finished initializing process group; backend: gloo, rank: 0, world_size: 2
param_size(GB) =  0.071971072
Send ranks:  {'out4': [1], 'out5': [1], 'target': [1]}
Receive ranks:  {}
Setting up process groups for broadcasts...
At epoch 0, run n = 8
latent_size(GB) =  2.734009344
latent_size(GB) =  2.717952512
Epoch: 0 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [0][0/8]	Memory: 5.741 (6.004) (5.791)
latent_size(GB) =  2.734009344
latent_size(GB) =  2.733026304
latent_size(GB) =  2.73505792
latent_size(GB) =  2.733026304
latent_size(GB) =  2.734992384
latent_size(GB) =  2.735188992
Epoch 0: 6.364 seconds
Epoch start time: 1597298691.700, epoch end time: 1597298698.064
At epoch 1, run n = 8
latent_size(GB) =  2.7337472
latent_size(GB) =  2.745936896
Epoch: 1 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [1][0/8]	Memory: 5.879 (6.558) (8.335)
latent_size(GB) =  2.73276416
latent_size(GB) =  2.735123456
latent_size(GB) =  2.732960768
latent_size(GB) =  2.733943808
latent_size(GB) =  2.733157376
latent_size(GB) =  2.734861312
Epoch 1: 3.541 seconds
Epoch start time: 1597298698.281, epoch end time: 1597298701.822
At epoch 2, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.738531328
Epoch: 2 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [2][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.733878272
latent_size(GB) =  2.73407488
latent_size(GB) =  2.73309184
latent_size(GB) =  2.734861312
latent_size(GB) =  2.73309184
latent_size(GB) =  2.734926848
Epoch 2: 2.143 seconds
Epoch start time: 1597298702.079, epoch end time: 1597298704.221
At epoch 3, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.738465792
Epoch: 3 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [3][0/8]	Memory: 5.905 (6.558) (8.335)
latent_size(GB) =  2.734009344
latent_size(GB) =  2.734009344
latent_size(GB) =  2.73309184
latent_size(GB) =  2.735778816
latent_size(GB) =  2.73309184
latent_size(GB) =  2.733943808
Epoch 3: 2.097 seconds
Epoch start time: 1597298704.502, epoch end time: 1597298706.599
At epoch 4, run n = 8
latent_size(GB) =  2.733681664
latent_size(GB) =  2.739514368
Epoch: 4 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [4][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.732895232
latent_size(GB) =  2.737089536
latent_size(GB) =  2.730994688
latent_size(GB) =  2.734795776
latent_size(GB) =  2.732043264
latent_size(GB) =  2.734926848
Epoch 4: 2.002 seconds
Epoch start time: 1597298706.894, epoch end time: 1597298708.896
At epoch 5, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.751310848
Epoch: 5 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [5][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.733943808
latent_size(GB) =  2.734992384
latent_size(GB) =  2.732043264
latent_size(GB) =  2.735909888
latent_size(GB) =  2.7321088
latent_size(GB) =  2.735975424
Epoch 5: 2.106 seconds
Epoch start time: 1597298709.168, epoch end time: 1597298711.274
At epoch 6, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.751310848
Epoch: 6 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [6][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.733943808
latent_size(GB) =  2.73604096
latent_size(GB) =  2.732043264
latent_size(GB) =  2.734795776
latent_size(GB) =  2.734140416
latent_size(GB) =  2.733878272
Epoch 6: 2.015 seconds
Epoch start time: 1597298711.547, epoch end time: 1597298713.561
At epoch 7, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.751310848
Epoch: 7 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [7][0/8]	Memory: 5.905 (6.558) (8.335)
latent_size(GB) =  2.733943808
latent_size(GB) =  2.73604096
latent_size(GB) =  2.732043264
latent_size(GB) =  2.734795776
latent_size(GB) =  2.733026304
latent_size(GB) =  2.734992384
Epoch 7: 2.367 seconds
Epoch start time: 1597298713.827, epoch end time: 1597298716.195
At epoch 8, run n = 8
latent_size(GB) =  2.73473024
latent_size(GB) =  2.735319552
Epoch: 8 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [8][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.733878272
latent_size(GB) =  2.73407488
latent_size(GB) =  2.73309184
latent_size(GB) =  2.734861312
latent_size(GB) =  2.73309184
latent_size(GB) =  2.733878272
Epoch 8: 2.190 seconds
Epoch start time: 1597298716.525, epoch end time: 1597298718.716
At epoch 9, run n = 8
latent_size(GB) =  2.733681664
latent_size(GB) =  2.752359424
Epoch: 9 Step 0 	Learning rate: 0.100000
Epoch(with batch 32): [9][0/8]	Memory: 5.908 (6.558) (8.335)
latent_size(GB) =  2.732895232
latent_size(GB) =  2.737089536
latent_size(GB) =  2.730994688
latent_size(GB) =  2.734795776
latent_size(GB) =  2.73309184
latent_size(GB) =  2.734926848
Epoch 9: 2.148 seconds
Epoch start time: 1597298718.989, epoch end time: 1597298721.137
